{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np; np.set_printoptions(precision=2); np.random.seed(0)\n",
    "import torch; torch.set_printoptions(precision=2)\n",
    "seed = 1\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib \n",
    "from matplotlib.font_manager import FontProperties\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pylab as pl\n",
    "from mpltern.ternary.datasets import get_scatter_points\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import time\n",
    "import sys\n",
    "import itertools \n",
    "import random; random.seed(0)\n",
    "import datetime\n",
    "import pickle\n",
    "import copy\n",
    "import pandas as pd\n",
    "import scipy; from scipy import stats; from scipy.stats import wilcoxon\n",
    "import os\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import sys\n",
    "\n",
    "# from model_working import *\n",
    "from functions import *\n",
    "\n",
    "print(torch.__version__)\n",
    "print(sys.version)\n",
    "                \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5c: bias in the input weight, one example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/.../conn_bias_sm_w_in.pickle', 'rb') as handle:\n",
    "    all_data = pickle.load(handle)\n",
    "\n",
    "\n",
    "data_fig5c = {'big': [], 'small': []}\n",
    "\n",
    "for data in all_data:\n",
    "    if data['model_name'] != 'success_2023-05-10-14-28-42_wcst_106_sparsity0':    # this is the example model\n",
    "        continue\n",
    "    w_in_larges = []\n",
    "    w_in_large_refs = []\n",
    "    w_in_large_tests = []\n",
    "    w_in_smalls = []\n",
    "    for r in [1, 2]:\n",
    "        for choice in [1, 2, 3]:\n",
    "            for card in ['(0, 0)', '(1, 0)', '(0, 1)', '(1, 1)']:\n",
    "                neuron_id_rule = data['subcg_sr_idx']['rule{}_sr_esoma'.format(r)]\n",
    "                neuron_id_choice = data['subcg_sr_idx']['respc{}_sr_esoma'.format(choice)]\n",
    "                neuron_id_refcard = data['subcg_sr_idx']['ref_card{}_sr_esoma'.format(card)]\n",
    "                neuron_id = [n for n in neuron_id_rule if (n in neuron_id_choice and n in neuron_id_refcard)]    # all neurons that prefer a given combination of rule, choice and reference card (and therefore feature)        \n",
    "                # print('rule {}, choice {}, card {}\\nneuron_id {}'.format(r, choice, card, neuron_id))\n",
    "                if (r==1 and (card=='(0, 0)' or card=='(0, 1)')) or (r==2 and (card=='(0, 0)' or card=='(1, 0)')):\n",
    "                    feature_id = 0    # this neuron prefers when the matching feature is blue or circle\n",
    "                else:\n",
    "                    feature_id = 1    # this neuron prefers when the matching feature is red or square \n",
    "#                 input_neuron_id_large = [2*(r-1) + feature_id, 4+4*(choice-1) + 2*(r-1) + feature_id]    # the indices of the input neurons that should have a strong projection to this neuron\n",
    "                input_neuron_id_large_ref = 2*(r-1) + feature_id\n",
    "                input_neuron_id_large_test = 4+4*(choice-1) + 2*(r-1) + feature_id\n",
    "                input_neuron_id_large = [input_neuron_id_large_ref, input_neuron_id_large_test]    # the indices of the input neurons that should have a strong projection to this neuron\n",
    "                input_neuron_id_small = [i for i in range(data['w_in_eff'].shape[0]) if i not in input_neuron_id_large]\n",
    "                for n in neuron_id:\n",
    "                    dend_id = [n + (b+1)*data['n_sr_esoma'] for b in range(data['n_branches'])]    # the dendritic indices\n",
    "                    w_in_large = data['w_in_eff'][np.ix_(input_neuron_id_large, dend_id)]\n",
    "                    w_in_small = data['w_in_eff'][np.ix_(input_neuron_id_small, dend_id)]\n",
    "                    w_in_large_ref = data['w_in_eff'][input_neuron_id_large_ref, dend_id]\n",
    "                    w_in_large_test = data['w_in_eff'][input_neuron_id_large_test, dend_id]\n",
    "                    \n",
    "                    w_in_larges.append(np.mean(w_in_large))\n",
    "                    w_in_smalls.append(np.mean(w_in_small))\n",
    "                    w_in_large_refs.append(np.mean(w_in_large_ref))\n",
    "                    w_in_large_tests.append(np.mean(w_in_large_test))\n",
    "                    \n",
    "    #=== plotting ===#\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for i in range(len(w_in_larges)):\n",
    "        ax.plot([w_in_larges[i], w_in_smalls[i]], marker='o', markersize=10, alpha=0.5, color='k')\n",
    "    y = [w_in_larges, w_in_smalls]\n",
    "    \n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_ylabel(r'Input weight', fontsize=20)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nfeature', 'Non-preferred\\nfeature'], rotation=0, fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # statistical test\n",
    "    t, p = scipy.stats.ttest_ind(y[0], y[1], alternative='greater')\n",
    "    print('t={}, p-value={}, n={}'.format(t, p, len(y[0])))\n",
    "\n",
    "    # save source data\n",
    "    data_fig5c['big'] = w_in_larges\n",
    "    data_fig5c['small'] = w_in_smalls\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary figure 9a, b: across all networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_suppfig9ab = {'subtractive': {}, 'divisive_2': {}}\n",
    "for key in data_suppfig9.keys():\n",
    "    data_suppfig9ab[key] = {'big': [], 'small': []}\n",
    "    \n",
    "for dend_nonlinear in ['subtractive', 'divisive_2']:\n",
    "    w_in_large_all_models = []\n",
    "    w_in_large_ref_all_models = []\n",
    "    w_in_large_test_all_models = []\n",
    "    w_in_small_all_models = []\n",
    "    for data in all_data:\n",
    "        if data['hp']['dend_nonlinearity'] != dend_nonlinear: \n",
    "            continue\n",
    "        w_in_larges = []\n",
    "        w_in_large_refs = []\n",
    "        w_in_large_tests = []\n",
    "        w_in_smalls = []\n",
    "        for r in [1, 2]:\n",
    "            for choice in [1, 2, 3]:\n",
    "                for card in ['(0, 0)', '(1, 0)', '(0, 1)', '(1, 1)']:\n",
    "                    neuron_id_rule = data['subcg_sr_idx']['rule{}_sr_esoma'.format(r)]\n",
    "                    neuron_id_choice = data['subcg_sr_idx']['respc{}_sr_esoma'.format(choice)]\n",
    "                    neuron_id_refcard = data['subcg_sr_idx']['ref_card{}_sr_esoma'.format(card)]\n",
    "                    neuron_id = [n for n in neuron_id_rule if (n in neuron_id_choice and n in neuron_id_refcard)]    # all neurons that prefer a given combination of rule, choice and reference card (and therefore feature)        \n",
    "                    if (r==1 and (card=='(0, 0)' or card=='(0, 1)')) or (r==2 and (card=='(0, 0)' or card=='(1, 0)')):\n",
    "                        feature_id = 0    # this neuron prefers when the matching feature is blue or circle\n",
    "                    else:\n",
    "                        feature_id = 1    # this neuron prefers when the matching feature is red or square \n",
    "                    input_neuron_id_large_ref = 2*(r-1) + feature_id\n",
    "                    input_neuron_id_large_test = 4+4*(choice-1) + 2*(r-1) + feature_id\n",
    "                    input_neuron_id_large = [input_neuron_id_large_ref, input_neuron_id_large_test]    # the indices of the input neurons that should have a strong projection to this neuron\n",
    "                    input_neuron_id_small = [i for i in range(data['w_in_eff'].shape[0]) if i not in input_neuron_id_large]\n",
    "                    for n in neuron_id:\n",
    "                        dend_id = [n + (b+1)*data['n_sr_esoma'] for b in range(data['n_branches'])]    # the dendritic indices\n",
    "                        w_in_large = data['w_in_eff'][np.ix_(input_neuron_id_large, dend_id)]\n",
    "                        w_in_small = data['w_in_eff'][np.ix_(input_neuron_id_small, dend_id)]\n",
    "                        w_in_large_ref = data['w_in_eff'][input_neuron_id_large_ref, dend_id]\n",
    "                        w_in_large_test = data['w_in_eff'][input_neuron_id_large_test, dend_id]\n",
    "                        \n",
    "                        w_in_larges.append(np.mean(w_in_large))\n",
    "                        w_in_smalls.append(np.mean(w_in_small))\n",
    "                        w_in_large_refs.append(np.mean(w_in_large_ref))\n",
    "                        w_in_large_tests.append(np.mean(w_in_large_test))\n",
    "    \n",
    "        w_in_large_all_models.extend(w_in_larges)\n",
    "        w_in_large_ref_all_models.extend(w_in_large_refs)\n",
    "        w_in_large_test_all_models.extend(w_in_large_tests)\n",
    "        w_in_small_all_models.extend(w_in_smalls)\n",
    "    \n",
    "    #=== plotting ===#\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.suptitle(dend_nonlinear)\n",
    "    fig.patch.set_facecolor('white')\n",
    "    for i in range(len(w_in_large_all_models)):\n",
    "        ax.plot([w_in_large_all_models[i], w_in_small_all_models[i]], marker='o', markersize=10, alpha=0.1, color='k')\n",
    "    y = [w_in_large_all_models, w_in_small_all_models]\n",
    "    \n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_ylabel(r'Input weight', fontsize=20)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nfeature', 'Non-preferred\\nfeature'], rotation=0, fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # statistical test\n",
    "    t, p = scipy.stats.ttest_ind(y[0], y[1], alternative='greater')\n",
    "    print('t={}, p-value={}, n={}'.format(t, p, len(y[0])))\n",
    "\n",
    "    # save source data\n",
    "    data_suppfig9ab[dend_nonlinear]['big'] = w_in_large_all_models\n",
    "    data_suppfig9ab[dend_nonlinear]['small'] = w_in_small_all_models\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 5d: w_out for an example model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/yl4317/Documents/two_module_rnn/processed_data/conn_bias_sm_w_out.pickle', 'rb') as handle:\n",
    "    all_data_wout = pickle.load(handle)\n",
    "\n",
    "data_fig5d = {'big': [], 'small': []}\n",
    "\n",
    "for data in all_data_wout:\n",
    "    if data['model_name'] != 'success_2023-05-10-14-28-42_wcst_136_sparsity0':    # this is the example model shown in the paper\n",
    "        continue\n",
    "    print(data['model_name'])\n",
    "    wout_pref = []\n",
    "    wout_nonpref = []\n",
    "    wout = data['w_out_eff']\n",
    "    for resp in ['c1', 'c2', 'c3']:\n",
    "        neuron_idx = data['subcg_sr_idx']['resp{}_sr_esoma'.format(resp)]\n",
    "        # print('resp {}, neuron_idx {}'.format(resp, neuron_idx))\n",
    "        if resp=='c1':\n",
    "            wout_idx_pref, wout_idx_nonpref = 0, [1, 2]\n",
    "        elif resp=='c2':\n",
    "            wout_idx_pref, wout_idx_nonpref = 1, [0, 2]\n",
    "        elif resp=='c3':\n",
    "            wout_idx_pref, wout_idx_nonpref = 2, [0, 1]\n",
    "        wout_pref.extend(wout[neuron_idx, wout_idx_pref])\n",
    "        wout_nonpref.extend(np.mean(wout[np.ix_(neuron_idx, wout_idx_nonpref)], axis=1))\n",
    "\n",
    "    #===== plotting =====#\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.plot([0, 1], [wout_pref, wout_nonpref], color='k', marker='o', alpha=0.5)\n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nchoice', 'Non-preferred\\nchoice'], rotation=0)\n",
    "    ax.set_ylabel('Readout weight', fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# statistical test\n",
    "t, p = scipy.stats.ttest_ind(wout_pref, wout_nonpref, alternative='greater')\n",
    "print('t={}, p-value={}, n={}'.format(t, p, len(wout_pref)))\n",
    "\n",
    "\n",
    "# collect source data\n",
    "data_fig5d['big'].extend(wout_pref)\n",
    "data_fig5d['small'].extend(wout_nonpref)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary Figure 9c, d: w_out, across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_suppfig19cd = {'subtractive': {}, 'divisive_2': {}}\n",
    "for key in data_suppfig19cd.keys():\n",
    "    data_suppfig19cd[key] = {'big': [], 'small': []}\n",
    "\n",
    "\n",
    "for dend_nonlinear in ['subtractive', 'divisive_2']:\n",
    "    wout_pref_all = []\n",
    "    wout_nonpref_all = []\n",
    "    for data in all_data_wout:\n",
    "        if data['hp']['dend_nonlinearity'] != dend_nonlinear:   \n",
    "            continue\n",
    "        # wout_pref = []\n",
    "        # wout_nonpref = []\n",
    "        wout = data['w_out_eff']\n",
    "        for resp in ['c1', 'c2', 'c3']:\n",
    "            neuron_idx = data['subcg_sr_idx']['resp{}_sr_esoma'.format(resp)]\n",
    "            if resp=='c1':\n",
    "                wout_idx_pref, wout_idx_nonpref = 0, [1, 2]\n",
    "            elif resp=='c2':\n",
    "                wout_idx_pref, wout_idx_nonpref = 1, [0, 2]\n",
    "            elif resp=='c3':\n",
    "                wout_idx_pref, wout_idx_nonpref = 2, [0, 1]\n",
    "            wout_pref_all.extend(wout[neuron_idx, wout_idx_pref])\n",
    "            wout_nonpref_all.extend(np.mean(wout[np.ix_(neuron_idx, wout_idx_nonpref)], axis=1))\n",
    "            \n",
    "    #===== plotting =====#\n",
    "    fig, ax = plt.subplots(figsize=[10,7])\n",
    "    fig.patch.set_facecolor('white')\n",
    "    ax.plot([0, 1], [wout_pref_all, wout_nonpref_all], color='k', marker='o', alpha=0.1)\n",
    "    ax.set_xlim([-0.2, 1.2])\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['Preferred\\nchoice', 'Non-preferred\\nchoice'], rotation=0)\n",
    "    ax.set_ylabel('Readout weight', fontsize=20)\n",
    "    make_pretty_axes(ax)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # statistical test\n",
    "    t, p = scipy.stats.ttest_ind(wout_pref_all, wout_nonpref_all, alternative='greater')\n",
    "    print('t={}, p-value={}, n={}'.format(t, p, len(wout_pref_all)))\n",
    "\n",
    "    \n",
    "    # collect source data\n",
    "    data_suppfig19cd[dend_nonlinear]['big'].extend(wout_pref_all)\n",
    "    data_suppfig19cd[dend_nonlinear]['small'].extend(wout_nonpref_all)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
